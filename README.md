# DADS7202_HW02 The pre-trained CNN

## Project title:



## Introduction: 

Nowadays there are a lot of mobile phones in the market there has a lot of unique function for their brand however the appearance of mobile phone are very the same make the customer very confused when they try to find a phone that they want "which one is the right one that I want?" or "Is this the phone that I'm looking for?" there is the most question when customer try to find the phone because when search mobile phone on Google sometime the picture that comes up looks like the brand that search but it isn't because of this problem our team come with the idea "Classification of mobile phone brand" to classified the picture of mobile phone which one is which brand from our discussion we choose 4 mobile phone's brand that we think it's easy to confuse and hard to tell which brand is the right one.

There are a lot of mobile phones in the market but **the appearance of every mobile phone are look the same** make it's hard for the customer to find a phone that they want.  even the photo of the phone on Google sometime the picture that comes up looks like the brand that search but it isn't. **Because of this problem our team come with the idea** **`"Classification of mobile phone brand"`** to classified the picture of mobile phone which one is which brand

* üì± **`Apple (iPhone)`**                      
* üì± **`Samsung`**
* üì± **`OPPO`**                              
* üì± **`Huawei`**


## Dataset
Link to download the dataset: https://drive.google.com/drive/folders/16B2ut6co3qQ1eBGqpvZMb8ZJNta62rp4?usp=sharing
How to labeling data?


## Assumption:

## Data pre-processing and splitting :
In the process, all images were converted to .jpg files and manually extracted into sub-folders separate by brand. Then, we resized the images by running tf.keras.preprocessing.image.load_img() function for loading the images with different heights and widths into PIL format, sizing 224 x 224 pixels as CNN models expect such a target size. A PIL Image instance was then converted to a Numpy array using tf.keras.preprocessing.image.img_to_array() function, returning a 3D Numpy array (501, 224, 224, 3). Last step, we also needed to run the images through a preprocess input function of the models we have used, such as tf.keras.applications.efficientnet.preprocess_input() for preprocessing the NumPy array encoding a batch of images.

## Data Augmentation :


How to split train/test set? manual or method?

## Pre-train model:
‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà Fine Tuning ‡πÑ‡∏î‡πâ

1. ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö Data Aug layer
2. Feature extraction
2.1 ‡πÅ‡∏Å‡πâ freeze ‡∏Ç‡∏≠‡∏á pre-train
2.2 ‡πÄ‡∏û‡∏¥‡πà‡∏° Convolution / pooling ‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å pre-train
3. ‡πÄ‡∏û‡∏¥‡πà‡∏°/‡∏õ‡∏£‡∏±‡∏ö Classifier layer


## Comparison performance:

1.VGG16

2.Mobilenet

3.inception-V3



## Training:




## Results:



## Discussion:
1.session crash due to ran out of RAM
![MicrosoftTeams-image (10)](https://user-images.githubusercontent.com/107410157/196458197-d0e59956-51d9-4be5-8566-edc6683d903c.png)



## Conclusion:



## References:



## üôã Deepsleep's Member:
| %|ID|Name |Responsibility  |
| :------ | ------ |:------|:-------|
|‚≠ê **`20%`** | **`6410414007`**  | üë¶ Athit Santikarn  |**`Collect data(Oppo)`**, **`Write result`**, **`conclusion report`**|
|‚≠ê **`20%`** | **`6410422020`**  | üë© Suphanun Sukamta |**`Collect data(Samsung)`**, **`Write result`**, **`conclusion report`**|
|‚≠ê **`20%`** | **`6410422004`**  | üë¶ Chokchai Kenpho  |**`Collect data(Apple)`**, **`Train model-VGG16`**|
|‚≠ê **`20%`** | **`6410422009`**  | üë¶ Noppol Anakpluek  |**`Preprocess data`**, **`Train model-ResNet152V2`**|
|‚≠ê **`20%`** | **`6420422006`**  | üë¶ Watcharakorn Pasanta  | **`Collect data(Huawei)`**, **`Train model-MobileNet`**|


## End credit: 
This project is a part of Course DADS7202 Deep Learning, Data Analytics and Data Science, NIDA.


Note : ‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô HW02

-‡πÉ‡∏´‡πâ‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û dataset

-‡πÄ‡∏õ‡πá‡∏ô dataset ‡∏ó‡∏µ‡πà pre-train ‡∏¢‡∏±‡∏á‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡πÑ‡∏°‡πà‡∏î‡∏µ

-‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 3 backbone(feature extracter) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ó‡∏≥‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ classifier

‡πÄ‡∏ä‡πà‡∏ô ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏à‡∏≤‡∏Å VGG ‡πÄ‡∏õ‡πá‡∏ô efficientDet ‡πÅ‡∏•‡πâ‡∏ß‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö

(‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô backbone ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏à‡∏∏‡∏î‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÅ‡∏•‡∏∞‡πÑ‡∏î‡πâ‡∏ú‡∏•‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î)

-‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô ‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏ú‡∏•‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ pre-train ‡∏î‡πâ‡∏ß‡∏¢‡∏ß‡πà‡∏≤ ‡∏ú‡∏•‡∏Å‡πà‡∏≠‡∏ô fine-tune ‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£ ‡πÅ‡∏•‡πâ‡∏ß‡∏ú‡∏•‡∏´‡∏•‡∏±‡∏á fune-tune ‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£
